# MAGIST PROJECT

* ### School
* ### Instructors
* ### Legend
* ### Medium Article
* ### Notebook


## School:
    
__WBS Web Coding School__

## Instructors
* Marlo Paßler
* Guy Fried


## Legend:
As a Junior Data Engineer at Gans, you’ll be tasked with developing an automated data pipeline in the cloud to collect, transform, and store data from various sources. This project will involve two major phases: building a local pipeline and migrating it to the cloud.

__Phase 1: Local pipeline__
Your first task will be to create a data pipeline locally, which involves collecting data from external sources, transforming it, and storing it in a SQL database. This will provide a foundation for building a scalable and automated pipeline in the cloud.
* Data Collection: web scraping
* Data Collection: APIs
* Data Storage: SQL database

__Phase 2: Cloud Pipeline__
Once the local pipeline is up and running, you’ll migrate it to the cloud using Google Cloud Platform (GCP). GCP offers numerous advantages for data pipelines, including scalability, flexibility, automation, and maintenance.
* GCP MySQL:
* Cloud Functions:
* Cloud Scheduler:

## Medium Article
You can find [article here](https://medium.com/@andrii.mekhanich/%D0%BC%D1%96%D0%B9-etl-%D0%BA%D0%BE%D0%BD%D0%B2%D0%B5%D1%94%D1%80-%D1%82%D0%B0-%D1%94%D0%B4%D0%B8%D0%BD%D0%B8%D0%B9-%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%96%D1%80-%D1%8F%D0%BA%D0%B8%D0%B9-%D0%BC%D0%B5%D0%BD%D0%B5-%D0%BC%D0%B0%D0%BB%D0%BE-%D0%BD%D0%B5-%D0%B7%D0%BB%D0%B0%D0%BC%D0%B0%D0%B2-79b8de3521e6).

## Notebook
You can find [notebook here](https://github.com/MekhAnd/Practice-DADS/blob/main/WBSCodingSchool/ETL_pipline_project/ETL_pipline_project.ipynb)

## List of Tools and Technologies
MySQL, GCP, Python, API, BeautifulSoup


